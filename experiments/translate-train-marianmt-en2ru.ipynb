{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Translate the English training set into Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "# model_name = \"facebook/wmt19-en-ru\"\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-ru'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detox_en_train = pd.read_csv('../data/english_data/en_data.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19766, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>toxic_comment</th>\n",
       "      <th>neutral_comment</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>toxic</th>\n",
       "      <th>confidence_toxic</th>\n",
       "      <th>is_match</th>\n",
       "      <th>confidence_is_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17341</th>\n",
       "      <td>150415</td>\n",
       "      <td>bitch , the japanese invented suicide bombing .</td>\n",
       "      <td>The japanese invented suicide bombing</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>reddit</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4583</th>\n",
       "      <td>57696</td>\n",
       "      <td>bitch he 19 fuckin feet</td>\n",
       "      <td>He is 19 feet</td>\n",
       "      <td>0.999144</td>\n",
       "      <td>twitter</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>23277</td>\n",
       "      <td>and fucking joel anthony is never open but he 's still dunking on my team</td>\n",
       "      <td>and joel anthony is never open but he 's still dunking on my team</td>\n",
       "      <td>0.991143</td>\n",
       "      <td>twitter</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16905</th>\n",
       "      <td>197758</td>\n",
       "      <td>shit is about to get real .</td>\n",
       "      <td>Problem is about to get real</td>\n",
       "      <td>0.996396</td>\n",
       "      <td>reddit</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16808</th>\n",
       "      <td>37406</td>\n",
       "      <td>so what the fuck was the interview ?</td>\n",
       "      <td>So what was the interview?</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>reddit</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx  \\\n",
       "17341  150415   \n",
       "4583    57696   \n",
       "6770    23277   \n",
       "16905  197758   \n",
       "16808   37406   \n",
       "\n",
       "                                                                   toxic_comment  \\\n",
       "17341                            bitch , the japanese invented suicide bombing .   \n",
       "4583                                                     bitch he 19 fuckin feet   \n",
       "6770   and fucking joel anthony is never open but he 's still dunking on my team   \n",
       "16905                                                shit is about to get real .   \n",
       "16808                                       so what the fuck was the interview ?   \n",
       "\n",
       "                                                         neutral_comment  \\\n",
       "17341                              The japanese invented suicide bombing   \n",
       "4583                                                       He is 19 feet   \n",
       "6770   and joel anthony is never open but he 's still dunking on my team   \n",
       "16905                                       Problem is about to get real   \n",
       "16808                                         So what was the interview?   \n",
       "\n",
       "       toxicity_score  dataset  toxic  confidence_toxic  is_match  \\\n",
       "17341        0.999186   reddit  False            0.9861      True   \n",
       "4583         0.999144  twitter  False            0.9885      True   \n",
       "6770         0.991143  twitter  False            0.9941      True   \n",
       "16905        0.996396   reddit  False            0.9972      True   \n",
       "16808        0.989000   reddit  False            0.9983      True   \n",
       "\n",
       "       confidence_is_match  \n",
       "17341               0.9837  \n",
       "4583                0.9388  \n",
       "6770                0.9426  \n",
       "16905               0.9625  \n",
       "16808               0.9887  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(text):\n",
    "    for symbol in \",.?'\":\n",
    "        text = text.replace(' ' + symbol, symbol)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(texts, num_beams=5, max_length='auto', **kwargs):\n",
    "    sentences = []\n",
    "    sent_sizes = []\n",
    "    for text in texts:\n",
    "        sents = sent_tokenize(detokenize(text))\n",
    "        sentences.extend(sents)\n",
    "        sent_sizes.append(len(sents))\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    if max_length == 'auto': \n",
    "        max_length = int(10 + inputs.input_ids.shape[1] * 1.5)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs.to(model.device), num_beams=num_beams, **kwargs)\n",
    "    out_sents = [tokenizer.decode(out, skip_special_tokens=True) for out in outputs]\n",
    "    out_texts = []\n",
    "    cursor = 0\n",
    "    for size in sent_sizes:\n",
    "        out_texts.append(' '.join(out_sents[cursor: cursor+size]))\n",
    "        cursor += size\n",
    "    return out_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he had steel balls too !',\n",
       " 'dude should have been taken to api , he would be right at home with all the other knuckleheads there',\n",
       " 'im not gonna sell the fucking picture , i just want to contribute to the fucking article .',\n",
       " 'the garbage that is being created by cnn and other news agencies is outrageous .',\n",
       " 'the reason they dont exist is because neither is a pathological liar like trump .']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.toxic_comment[:5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['У него тоже были стальные яйца!',\n",
       " 'Чувак должен был быть в Апи, он был бы прямо дома со всеми другими болванами.',\n",
       " 'Я не собираюсь продавать эту чертову фотографию, я просто хочу внести свой вклад в эту грёбаную статью.',\n",
       " 'Отбросы, которые создают КНН и другие агентства новостей, возмутительны.',\n",
       " 'Причина, по которой их не существует, в том, что и патологический лжец не похож на тромпа.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(detox_en_train.toxic_comment[:5].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Он тоже был храбрым!',\n",
       " 'Было бы неплохо, если бы он пошёл в Апи. Он подойдет.',\n",
       " 'Я не собираюсь продавать фотографию, я просто хочу внести свой вклад в статью.',\n",
       " 'Новости, которые создают КНН и другие новостные агентства, возмутительны.',\n",
       " 'Причина, по которой их не существует, в том, что ни они, ни они не лгут, как лошадь.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(detox_en_train.neutral_comment[:5].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  # 15 minutes to translate the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976d4bd8b33743858f2286d5241de983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxic_ru = []\n",
    "neutral_ru = []\n",
    "for i in trange(0, len(detox_en_train), batch_size):\n",
    "    toxic_ru.extend(translate(detox_en_train.toxic_comment[i:i+batch_size].tolist()))\n",
    "    neutral_ru.extend(translate(detox_en_train.neutral_comment[i:i+batch_size].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "detox_en_train['toxic_ru'] = toxic_ru\n",
    "detox_en_train['neutral_ru'] = neutral_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>toxic_comment</th>\n",
       "      <th>neutral_comment</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>toxic</th>\n",
       "      <th>confidence_toxic</th>\n",
       "      <th>is_match</th>\n",
       "      <th>confidence_is_match</th>\n",
       "      <th>toxic_ru</th>\n",
       "      <th>neutral_ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>61014</td>\n",
       "      <td>i 'll keeepu updated on what time ima be there cus i got school n shit</td>\n",
       "      <td>i 'll keeepu updated on what time ima be there cus i got school n stuff</td>\n",
       "      <td>0.985635</td>\n",
       "      <td>twitter</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>Я расскажу, в какое время Има будет там, я получу школьное дерьмо.</td>\n",
       "      <td>Я расскажу, в какое время мы будем там, я пойду в школу.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>85039</td>\n",
       "      <td>who the fvck wrote this article ?</td>\n",
       "      <td>Who wrote this article ?</td>\n",
       "      <td>0.956034</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>Кто, чёрт возьми, написал эту статью?</td>\n",
       "      <td>Кто написал эту статью?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17221</th>\n",
       "      <td>98951</td>\n",
       "      <td>i hope they 've sorted their shit out for the next election .</td>\n",
       "      <td>i hope they 've sorted their works out for the next election .</td>\n",
       "      <td>0.983750</td>\n",
       "      <td>reddit</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9904</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>Надеюсь, они разберутся со своим дерьмом на следующих выборах.</td>\n",
       "      <td>Надеюсь, они уладили свои дела на следующих выборах.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10526</th>\n",
       "      <td>11607</td>\n",
       "      <td>you can add 3 &amp; 1 internet to the shit list</td>\n",
       "      <td>You can add 3 &amp;1  internet to the list</td>\n",
       "      <td>0.995667</td>\n",
       "      <td>twitter</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>Вы можете добавить 3 и 1 интернет в список дерьма</td>\n",
       "      <td>Вы можете добавить 3 &amp;lt; 1 Интернет к списку</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14304</th>\n",
       "      <td>182334</td>\n",
       "      <td>where the fuck did you get that from ? ?</td>\n",
       "      <td>where  did you get that from ? ?</td>\n",
       "      <td>0.997454</td>\n",
       "      <td>reddit</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>Откуда, блядь, это у тебя? ?</td>\n",
       "      <td>Откуда это у тебя? ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx  \\\n",
       "6253    61014   \n",
       "2536    85039   \n",
       "17221   98951   \n",
       "10526   11607   \n",
       "14304  182334   \n",
       "\n",
       "                                                                toxic_comment  \\\n",
       "6253   i 'll keeepu updated on what time ima be there cus i got school n shit   \n",
       "2536                                        who the fvck wrote this article ?   \n",
       "17221           i hope they 've sorted their shit out for the next election .   \n",
       "10526                             you can add 3 & 1 internet to the shit list   \n",
       "14304                                where the fuck did you get that from ? ?   \n",
       "\n",
       "                                                               neutral_comment  \\\n",
       "6253   i 'll keeepu updated on what time ima be there cus i got school n stuff   \n",
       "2536                                                  Who wrote this article ?   \n",
       "17221           i hope they 've sorted their works out for the next election .   \n",
       "10526                                   You can add 3 &1  internet to the list   \n",
       "14304                                         where  did you get that from ? ?   \n",
       "\n",
       "       toxicity_score  dataset  toxic  confidence_toxic  is_match  \\\n",
       "6253         0.985635  twitter  False            0.9998      True   \n",
       "2536         0.956034   jigsaw  False            0.9748      True   \n",
       "17221        0.983750   reddit  False            0.9904      True   \n",
       "10526        0.995667  twitter  False            0.9512      True   \n",
       "14304        0.997454   reddit  False            0.9987      True   \n",
       "\n",
       "       confidence_is_match  \\\n",
       "6253                0.9973   \n",
       "2536                0.9906   \n",
       "17221               0.9789   \n",
       "10526               0.9749   \n",
       "14304               0.9750   \n",
       "\n",
       "                                                                 toxic_ru  \\\n",
       "6253   Я расскажу, в какое время Има будет там, я получу школьное дерьмо.   \n",
       "2536                                Кто, чёрт возьми, написал эту статью?   \n",
       "17221      Надеюсь, они разберутся со своим дерьмом на следующих выборах.   \n",
       "10526                   Вы можете добавить 3 и 1 интернет в список дерьма   \n",
       "14304                                        Откуда, блядь, это у тебя? ?   \n",
       "\n",
       "                                                     neutral_ru  \n",
       "6253   Я расскажу, в какое время мы будем там, я пойду в школу.  \n",
       "2536                                    Кто написал эту статью?  \n",
       "17221      Надеюсь, они уладили свои дела на следующих выборах.  \n",
       "10526             Вы можете добавить 3 &lt; 1 Интернет к списку  \n",
       "14304                                      Откуда это у тебя? ?  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023474653445310127"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(detox_en_train.toxic_ru == detox_en_train.neutral_ru).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19766.000000\n",
       "mean        54.972276\n",
       "std         23.354563\n",
       "min         11.000000\n",
       "25%         37.000000\n",
       "50%         51.000000\n",
       "75%         70.000000\n",
       "max        510.000000\n",
       "Name: toxic_ru, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.toxic_ru.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19766.000000\n",
       "mean        47.182687\n",
       "std         23.409306\n",
       "min          1.000000\n",
       "25%         29.000000\n",
       "50%         43.000000\n",
       "75%         62.000000\n",
       "max        510.000000\n",
       "Name: neutral_ru, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.neutral_ru.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textdistance import levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "detox_en_train['edit_distance_en'] = [levenshtein.distance(*row) for row in detox_en_train[['toxic_comment', 'neutral_comment']].values]\n",
    "detox_en_train['edit_distance_ru'] = [levenshtein.distance(*row) for row in detox_en_train[['toxic_ru', 'neutral_ru']].values]\n",
    "\n",
    "detox_en_train['edit_sim_en'] = [levenshtein.normalized_similarity(*row) for row in detox_en_train[['toxic_comment', 'neutral_comment']].values]\n",
    "detox_en_train['edit_sim_ru'] = [levenshtein.normalized_similarity(*row) for row in detox_en_train[['toxic_ru', 'neutral_ru']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>confidence_toxic</th>\n",
       "      <th>confidence_is_match</th>\n",
       "      <th>edit_distance_en</th>\n",
       "      <th>edit_distance_ru</th>\n",
       "      <th>edit_sim_en</th>\n",
       "      <th>edit_sim_ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.00000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78035.783416</td>\n",
       "      <td>0.990181</td>\n",
       "      <td>0.984174</td>\n",
       "      <td>0.972585</td>\n",
       "      <td>15.705757</td>\n",
       "      <td>21.46327</td>\n",
       "      <td>0.696492</td>\n",
       "      <td>0.602780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>60839.351686</td>\n",
       "      <td>0.019532</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>0.025094</td>\n",
       "      <td>10.989535</td>\n",
       "      <td>14.26659</td>\n",
       "      <td>0.186762</td>\n",
       "      <td>0.209683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.800983</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31839.000000</td>\n",
       "      <td>0.991065</td>\n",
       "      <td>0.981100</td>\n",
       "      <td>0.961100</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>63895.000000</td>\n",
       "      <td>0.996133</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>0.980500</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.626667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101255.250000</td>\n",
       "      <td>0.998179</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.991100</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>238836.000000</td>\n",
       "      <td>0.999647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>271.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 idx  toxicity_score  confidence_toxic  confidence_is_match  \\\n",
       "count   19766.000000    19766.000000      19766.000000         19766.000000   \n",
       "mean    78035.783416        0.990181          0.984174             0.972585   \n",
       "std     60839.351686        0.019532          0.025847             0.025094   \n",
       "min         7.000000        0.800983          0.523700             0.800000   \n",
       "25%     31839.000000        0.991065          0.981100             0.961100   \n",
       "50%     63895.000000        0.996133          0.994100             0.980500   \n",
       "75%    101255.250000        0.998179          0.998500             0.991100   \n",
       "max    238836.000000        0.999647          1.000000             0.999900   \n",
       "\n",
       "       edit_distance_en  edit_distance_ru   edit_sim_en   edit_sim_ru  \n",
       "count      19766.000000       19766.00000  19766.000000  19766.000000  \n",
       "mean          15.705757          21.46327      0.696492      0.602780  \n",
       "std           10.989535          14.26659      0.186762      0.209683  \n",
       "min            0.000000           0.00000      0.000000      0.000000  \n",
       "25%            8.000000          11.00000      0.590909      0.451613  \n",
       "50%           12.000000          18.00000      0.741935      0.626667  \n",
       "75%           20.000000          28.00000      0.838710      0.765957  \n",
       "max          105.000000         271.00000      1.000000      1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edit_distance_en</th>\n",
       "      <th>edit_sim_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.99</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      edit_distance_en  edit_sim_en\n",
       "0.01               3.0     0.192308\n",
       "0.05               5.0     0.312500\n",
       "0.90              30.0     0.900000\n",
       "0.99              56.0     0.961538"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train[['edit_distance_en', 'edit_sim_en']].quantile([0.01, 0.05, 0.90, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027876150966305777\n",
      "0.024435900030355156\n",
      "0.028230294445006576\n",
      "0.027066680157846808\n"
     ]
    }
   ],
   "source": [
    "# detox_en_train[['edit_distance_en', 'edit_sim_en']].quantile([0.01, 0.05, 0.90, 0.99])\n",
    "print((detox_en_train.edit_distance_ru < 3).mean())\n",
    "print((detox_en_train.edit_distance_ru > 56).mean())\n",
    "\n",
    "print((detox_en_train.edit_sim_ru < 0.19).mean())\n",
    "print((detox_en_train.edit_sim_ru > 0.96).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the resulting pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_ru import evaluate_style_transfer, rotation_calibration, load_model\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/LaBSE-en-ru were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "style_model, style_tokenizer = load_model(\n",
    "    \"SkolkovoInstitute/russian_toxicity_classifier\", use_cuda=True\n",
    ")\n",
    "meaning_model, meaning_tokenizer = load_model(\n",
    "    \"cointegrated/LaBSE-en-ru\", use_cuda=True, model_class=AutoModel\n",
    ")\n",
    "cola_model, cola_tolenizer = load_model(\n",
    "    \"SkolkovoInstitute/rubert-base-corruption-detector\", use_cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(original, rewritten):\n",
    "    return evaluate_style_transfer(\n",
    "        original_texts=original,\n",
    "        rewritten_texts=rewritten,\n",
    "        style_model=style_model,\n",
    "        style_tokenizer=style_tokenizer,\n",
    "        meaning_model=meaning_model,\n",
    "        meaning_tokenizer=meaning_tokenizer,\n",
    "        cola_model=cola_model,\n",
    "        cola_tokenizer=cola_tolenizer,\n",
    "        style_target_label=0,\n",
    "        aggregate=False,\n",
    "        style_calibration=lambda x: rotation_calibration(x, 0.90),\n",
    "        meaning_calibration=lambda x: rotation_calibration(x, 1.50),\n",
    "        fluency_calibration=lambda x: rotation_calibration(x, 1.15, px=0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style evaluation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3a7af16d964d81b06888cf047e94a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meaning evaluation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303a4e4b1c824c8993ea084436b62038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9eed3a733dd4b21a5e771f7ef85e0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluency evaluation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b59e510fc64484e90d79f7f7194ff54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f14b4fd1d844618fc0b35610e1bce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style accuracy:       0.8201743364334106\n",
      "Meaning preservation: 0.8069980144500732\n",
      "Joint fluency:        -0.11377539485692978\n",
      "Joint score:          -0.07197614014148712\n",
      "Scores after calibration:\n",
      "Style accuracy:       0.8381569385528564\n",
      "Meaning preservation: 0.711837887763977\n",
      "Joint fluency:        0.8691589832305908\n",
      "Joint score:          0.5257280468940735\n"
     ]
    }
   ],
   "source": [
    "eval_result = evaluate(detox_en_train.toxic_ru.tolist(), detox_en_train.neutral_ru.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'toxic_comment', 'neutral_comment', 'toxicity_score', 'dataset',\n",
       "       'toxic', 'confidence_toxic', 'is_match', 'confidence_is_match',\n",
       "       'toxic_ru', 'neutral_ru', 'edit_distance_en', 'edit_distance_ru',\n",
       "       'edit_sim_en', 'edit_sim_ru'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "detox_en2ru = pd.concat([\n",
    "    detox_en_train, \n",
    "    pd.DataFrame(eval_result)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19766, 19)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en2ru.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>confidence_toxic</th>\n",
       "      <th>confidence_is_match</th>\n",
       "      <th>edit_distance_en</th>\n",
       "      <th>edit_distance_ru</th>\n",
       "      <th>edit_sim_en</th>\n",
       "      <th>edit_sim_ru</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>similarity</th>\n",
       "      <th>fluency</th>\n",
       "      <th>joint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.00000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78035.783416</td>\n",
       "      <td>0.990181</td>\n",
       "      <td>0.984174</td>\n",
       "      <td>0.972585</td>\n",
       "      <td>15.705757</td>\n",
       "      <td>21.46327</td>\n",
       "      <td>0.696492</td>\n",
       "      <td>0.602780</td>\n",
       "      <td>0.838157</td>\n",
       "      <td>0.711838</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.525728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>60839.351686</td>\n",
       "      <td>0.019532</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>0.025094</td>\n",
       "      <td>10.989535</td>\n",
       "      <td>14.26659</td>\n",
       "      <td>0.186762</td>\n",
       "      <td>0.209683</td>\n",
       "      <td>0.250159</td>\n",
       "      <td>0.216294</td>\n",
       "      <td>0.172396</td>\n",
       "      <td>0.261383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.800983</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31839.000000</td>\n",
       "      <td>0.991065</td>\n",
       "      <td>0.981100</td>\n",
       "      <td>0.961100</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.604774</td>\n",
       "      <td>0.788633</td>\n",
       "      <td>0.309918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>63895.000000</td>\n",
       "      <td>0.996133</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>0.980500</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.974691</td>\n",
       "      <td>0.764827</td>\n",
       "      <td>0.944624</td>\n",
       "      <td>0.554619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101255.250000</td>\n",
       "      <td>0.998179</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.991100</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.994927</td>\n",
       "      <td>0.873708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>238836.000000</td>\n",
       "      <td>0.999647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>271.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 idx  toxicity_score  confidence_toxic  confidence_is_match  \\\n",
       "count   19766.000000    19766.000000      19766.000000         19766.000000   \n",
       "mean    78035.783416        0.990181          0.984174             0.972585   \n",
       "std     60839.351686        0.019532          0.025847             0.025094   \n",
       "min         7.000000        0.800983          0.523700             0.800000   \n",
       "25%     31839.000000        0.991065          0.981100             0.961100   \n",
       "50%     63895.000000        0.996133          0.994100             0.980500   \n",
       "75%    101255.250000        0.998179          0.998500             0.991100   \n",
       "max    238836.000000        0.999647          1.000000             0.999900   \n",
       "\n",
       "       edit_distance_en  edit_distance_ru   edit_sim_en   edit_sim_ru  \\\n",
       "count      19766.000000       19766.00000  19766.000000  19766.000000   \n",
       "mean          15.705757          21.46327      0.696492      0.602780   \n",
       "std           10.989535          14.26659      0.186762      0.209683   \n",
       "min            0.000000           0.00000      0.000000      0.000000   \n",
       "25%            8.000000          11.00000      0.590909      0.451613   \n",
       "50%           12.000000          18.00000      0.741935      0.626667   \n",
       "75%           20.000000          28.00000      0.838710      0.765957   \n",
       "max          105.000000         271.00000      1.000000      1.000000   \n",
       "\n",
       "           accuracy    similarity       fluency         joint  \n",
       "count  19766.000000  19766.000000  19766.000000  19766.000000  \n",
       "mean       0.838157      0.711838      0.869159      0.525728  \n",
       "std        0.250159      0.216294      0.172396      0.261383  \n",
       "min        0.103904      0.000000      0.000000      0.000000  \n",
       "25%        0.793939      0.604774      0.788633      0.309918  \n",
       "50%        0.974691      0.764827      0.944624      0.554619  \n",
       "75%        0.994927      0.873708      1.000000      0.745741  \n",
       "max        0.999766      1.000000      1.000000      0.999527  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en2ru.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "detox_en2ru[['accuracy', 'similarity', 'fluency', 'joint']].hist(bins=50, figsize=(12, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "detox_en2ru.to_csv('detox_en2ru.tsv', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the Russian model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detox_en2ru = pd.read_csv('detox_en2ru.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter text pairs by similarity to escape translation artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19766, 19)\n",
      "(18239, 19)\n"
     ]
    }
   ],
   "source": [
    "detox_en2ru_filtered = detox_en2ru[\n",
    "    (detox_en2ru.edit_distance_ru >= detox_en2ru.edit_distance_en.quantile(0.01)) \n",
    "    & (detox_en2ru.edit_distance_ru <= detox_en2ru.edit_distance_en.quantile(0.99)) \n",
    "    & (detox_en2ru.edit_sim_ru >= detox_en2ru.edit_sim_en.quantile(0.01)) \n",
    "    & (detox_en2ru.edit_sim_ru <= detox_en2ru.edit_sim_en.quantile(0.99))\n",
    "]\n",
    "\n",
    "print(detox_en2ru.shape)\n",
    "print(detox_en2ru_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(detox_en2ru_filtered, random_state=1, test_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.joint.hist(bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    17739.000000\n",
       "mean         0.534140\n",
       "std          0.250634\n",
       "min          0.000000\n",
       "25%          0.331690\n",
       "50%          0.563604\n",
       "75%          0.745561\n",
       "max          0.992979\n",
       "Name: joint, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.joint.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_50 = train[train.joint >= train.joint.quantile(0.5)]\n",
    "train_75 = train[train.joint >= train.joint.quantile(0.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>confidence_toxic</th>\n",
       "      <th>confidence_is_match</th>\n",
       "      <th>edit_distance_en</th>\n",
       "      <th>edit_distance_ru</th>\n",
       "      <th>edit_sim_en</th>\n",
       "      <th>edit_sim_ru</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>similarity</th>\n",
       "      <th>fluency</th>\n",
       "      <th>joint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13304.000000</td>\n",
       "      <td>13304.000000</td>\n",
       "      <td>13304.000000</td>\n",
       "      <td>13304.000000</td>\n",
       "      <td>13304.000000</td>\n",
       "      <td>13304.000000</td>\n",
       "      <td>13304.000000</td>\n",
       "      <td>13304.000000</td>\n",
       "      <td>13304.000000</td>\n",
       "      <td>13304.000000</td>\n",
       "      <td>13304.000000</td>\n",
       "      <td>13304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81179.148903</td>\n",
       "      <td>0.989729</td>\n",
       "      <td>0.985415</td>\n",
       "      <td>0.973341</td>\n",
       "      <td>13.799985</td>\n",
       "      <td>19.277661</td>\n",
       "      <td>0.737725</td>\n",
       "      <td>0.648702</td>\n",
       "      <td>0.930931</td>\n",
       "      <td>0.774121</td>\n",
       "      <td>0.904665</td>\n",
       "      <td>0.649284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62592.168793</td>\n",
       "      <td>0.019522</td>\n",
       "      <td>0.022921</td>\n",
       "      <td>0.024405</td>\n",
       "      <td>8.486507</td>\n",
       "      <td>10.850949</td>\n",
       "      <td>0.152123</td>\n",
       "      <td>0.167680</td>\n",
       "      <td>0.119426</td>\n",
       "      <td>0.138197</td>\n",
       "      <td>0.125325</td>\n",
       "      <td>0.167927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.800983</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.360933</td>\n",
       "      <td>0.338543</td>\n",
       "      <td>0.363357</td>\n",
       "      <td>0.331703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32820.500000</td>\n",
       "      <td>0.990162</td>\n",
       "      <td>0.982900</td>\n",
       "      <td>0.961800</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.534208</td>\n",
       "      <td>0.930174</td>\n",
       "      <td>0.686746</td>\n",
       "      <td>0.843657</td>\n",
       "      <td>0.513213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>65873.000000</td>\n",
       "      <td>0.995686</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>0.981100</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.672003</td>\n",
       "      <td>0.985912</td>\n",
       "      <td>0.799477</td>\n",
       "      <td>0.962577</td>\n",
       "      <td>0.658521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>110642.000000</td>\n",
       "      <td>0.997891</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.991400</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.996171</td>\n",
       "      <td>0.883814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.786931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>238832.000000</td>\n",
       "      <td>0.999645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 idx  toxicity_score  confidence_toxic  confidence_is_match  \\\n",
       "count   13304.000000    13304.000000      13304.000000         13304.000000   \n",
       "mean    81179.148903        0.989729          0.985415             0.973341   \n",
       "std     62592.168793        0.019522          0.022921             0.024405   \n",
       "min        13.000000        0.800983          0.556700             0.800000   \n",
       "25%     32820.500000        0.990162          0.982900             0.961800   \n",
       "50%     65873.000000        0.995686          0.994100             0.981100   \n",
       "75%    110642.000000        0.997891          0.998700             0.991400   \n",
       "max    238832.000000        0.999645          1.000000             0.999900   \n",
       "\n",
       "       edit_distance_en  edit_distance_ru   edit_sim_en   edit_sim_ru  \\\n",
       "count      13304.000000      13304.000000  13304.000000  13304.000000   \n",
       "mean          13.799985         19.277661      0.737725      0.648702   \n",
       "std            8.486507         10.850949      0.152123      0.167680   \n",
       "min            1.000000          3.000000      0.125000      0.192308   \n",
       "25%            8.000000         11.000000      0.653846      0.534208   \n",
       "50%           11.000000         17.000000      0.769231      0.672003   \n",
       "75%           17.000000         25.250000      0.852941      0.781818   \n",
       "max           73.000000         56.000000      0.982143      0.961039   \n",
       "\n",
       "           accuracy    similarity       fluency         joint  \n",
       "count  13304.000000  13304.000000  13304.000000  13304.000000  \n",
       "mean       0.930931      0.774121      0.904665      0.649284  \n",
       "std        0.119426      0.138197      0.125325      0.167927  \n",
       "min        0.360933      0.338543      0.363357      0.331703  \n",
       "25%        0.930174      0.686746      0.843657      0.513213  \n",
       "50%        0.985912      0.799477      0.962577      0.658521  \n",
       "75%        0.996171      0.883814      1.000000      0.786931  \n",
       "max        0.999766      0.999374      1.000000      0.992979  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_75.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 17739\n",
       "    })\n",
       "    train_50: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 8870\n",
       "    })\n",
       "    train_75: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 13304\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = DatasetDict({\n",
    "    'train': Dataset.from_dict({'text': train.toxic_ru, 'target': train.neutral_ru}),\n",
    "    'train_50': Dataset.from_dict({'text': train_50.toxic_ru, 'target': train_50.neutral_ru}),\n",
    "    'train_75': Dataset.from_dict({'text': train_75.toxic_ru, 'target': train_75.neutral_ru}),\n",
    "    'dev': Dataset.from_dict({'text': val.toxic_ru, 'target': val.neutral_ru}),\n",
    "})\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and evaluate baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu import CHRF\n",
    "chrfpp = CHRF(word_order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline chrf++: 60% if not change the texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.6204444270353"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrfpp.corpus_score(val.toxic_ru.tolist(), [val.neutral_ru.tolist()]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A baseline that removes bad words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import wordpunct_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "def detokenize(text):\n",
    "    for symbol in \",.?!'\":\n",
    "        text = text.replace(' ' + symbol, symbol)\n",
    "    return text\n",
    "\n",
    "class Remover:\n",
    "    def __init__(self, ratio_threshold=2):\n",
    "        self.ratio_threshold = ratio_threshold\n",
    "    def fit(self, x, y):\n",
    "        self.x_count = Counter(w.lower() for text in x for w in wordpunct_tokenize(text))\n",
    "        self.y_count = Counter(w.lower() for text in y for w in wordpunct_tokenize(text))\n",
    "    def predict(self, x):\n",
    "        results = []\n",
    "        for text in x:\n",
    "            words = []\n",
    "            for w in wordpunct_tokenize(text):\n",
    "                key = w.lower()\n",
    "                if (self.x_count[key] + 1) / (self.y_count[key] + 1) > self.ratio_threshold:\n",
    "                    continue\n",
    "                words.append(w)\n",
    "            results.append(detokenize(' '.join(words)))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = Remover(2.0)\n",
    "remover.fit(train.toxic_ru, train.neutral_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.37180546341031"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrfpp.corpus_score(remover.predict(val.toxic_ru), [val.neutral_ru.tolist()]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple word-based translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from itertools import product\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# https://johnlekberg.com/blog/2020-10-25-seq-align.html\n",
    "\n",
    "\n",
    "def needleman_wunsch(x, y, sim=None, verbose=False):\n",
    "    \"\"\"Run the Needleman-Wunsch algorithm on two sequences.\n",
    "\n",
    "    x, y -- sequences.\n",
    "\n",
    "    Code based on pseudocode in Section 3 of:\n",
    "\n",
    "    Naveed, Tahir; Siddiqui, Imitaz Saeed; Ahmed, Shaftab.\n",
    "    \"Parallel Needleman-Wunsch Algorithm for Grid.\" n.d.\n",
    "    https://upload.wikimedia.org/wikipedia/en/c/c4/ParallelNeedlemanAlgorithm.pdf\n",
    "    \"\"\"\n",
    "    N, M = len(x), len(y)\n",
    "    if sim is None:\n",
    "        s = lambda a, b: int(a == b)\n",
    "    else:\n",
    "        s = sim\n",
    "\n",
    "    DIAG = -1, -1\n",
    "    LEFT = -1, 0\n",
    "    UP = 0, -1\n",
    "\n",
    "    # Create tables F and Ptr\n",
    "    F = {}\n",
    "    Ptr = {}\n",
    "\n",
    "    F[-1, -1] = 0\n",
    "    for i in range(N):\n",
    "        F[i, -1] = -i\n",
    "    for j in range(M):\n",
    "        F[-1, j] = -j\n",
    "\n",
    "    option_Ptr = DIAG, LEFT, UP\n",
    "    for i, j in product(range(N), range(M)):\n",
    "        option_F = (\n",
    "            F[i - 1, j - 1] + s(x[i], y[j]),\n",
    "            F[i - 1, j] - 1,\n",
    "            F[i, j - 1] - 1,\n",
    "        )\n",
    "        F[i, j], Ptr[i, j] = max(zip(option_F, option_Ptr))\n",
    "\n",
    "    # Work backwards from (N - 1, M - 1) to (0, 0)\n",
    "    # to find the best alignment.\n",
    "    alignment = deque()\n",
    "    i, j = N - 1, M - 1\n",
    "    if verbose:\n",
    "        tq = tqdm(total=max(N, M))\n",
    "        \n",
    "    while i >= 0 and j >= 0:\n",
    "        direction = Ptr[i, j]\n",
    "        if direction == DIAG:\n",
    "            element = i, j\n",
    "        elif direction == LEFT:\n",
    "            element = i, None\n",
    "        elif direction == UP:\n",
    "            element = None, j\n",
    "        alignment.appendleft(element)\n",
    "        di, dj = direction\n",
    "        i, j = i + di, j + dj\n",
    "    while i >= 0:\n",
    "        alignment.appendleft((i, None))\n",
    "        i -= 1\n",
    "    while j >= 0:\n",
    "        alignment.appendleft((None, j))\n",
    "        j -= 1\n",
    "\n",
    "    return list(alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "from tqdm.auto import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TextReplacer:\n",
    "    def __init__(self, max_n=3, smooth_n=10, min_n=10, min_p=0.01):\n",
    "        self.max_n = max_n\n",
    "        self.smooth_n = smooth_n\n",
    "        self.min_n = min_n\n",
    "        self.min_p = min_p\n",
    "        \n",
    "        self.replace_proba = {}\n",
    "        self.replaced_tuples = {}\n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        return nltk.wordpunct_tokenize('_bos_ ' + text + ' _eos_')\n",
    "    \n",
    "    def detokenize(self, text):\n",
    "        text = text.strip()\n",
    "        for symbol in '.,?!':\n",
    "            text = text.replace(' ' + symbol, symbol)\n",
    "        if text.startswith('_bos_'):\n",
    "            text = text[5:]\n",
    "        if text.endswith('_eos_'):\n",
    "            text = text[:-5]\n",
    "        return text.strip()\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        raw_counts = Counter()\n",
    "        replace_counts = Counter()\n",
    "        \n",
    "        for i in trange(len(x_train)):\n",
    "            xx, yy = x_train[i], y_train[i]\n",
    "            xx, yy = self.tokenize(xx), self.tokenize(yy)\n",
    "            alignment = needleman_wunsch(xx, yy)\n",
    "            ixx, iyy = list(zip(*alignment))\n",
    "            for gram_size in range(1, self.max_n + 1):\n",
    "                for start in range(len(ixx) - gram_size + 1):\n",
    "                    xgram = tuple([xx[c] for c in ixx[start: start + gram_size] if c is not None])\n",
    "                    ygram = tuple([yy[c] for c in iyy[start: start + gram_size] if c is not None])\n",
    "                    if xgram:\n",
    "                        xg, yg = ' '.join([''] + list(xgram) + ['']), ' '.join([''] + list(ygram) + [''])\n",
    "                        raw_counts[xg] += 1\n",
    "                        if xgram != ygram:\n",
    "                            replace_counts[(xg, yg)] += 1\n",
    "    \n",
    "        self.replace_proba = defaultdict(list)\n",
    "        self.replaced_tuples = dict()\n",
    "\n",
    "        for pair, n_sub in replace_counts.most_common():\n",
    "            if n_sub >= self.min_n:\n",
    "                xx, yy = pair\n",
    "                pr = n_sub / (self.smooth_n + raw_counts[xx])\n",
    "                if pr >= self.min_p:\n",
    "                    self.replace_proba[xx].append([yy, pr])\n",
    "                    self.replaced_tuples[tuple(xx.strip().split())] = raw_counts[xx]\n",
    "\n",
    "        for k, v in self.replace_proba.items():\n",
    "            tot = sum(p for r, p in v)\n",
    "            if tot < 1:\n",
    "                v.append([k, 1 - tot])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform_one(self, text, n_out=None, temperature=None):\n",
    "        xx = self.tokenize(text)\n",
    "        found_grams = []\n",
    "        for gram_size in range(1, self.max_n + 1):\n",
    "            for start in range(len(xx) - gram_size + 1):\n",
    "                xgram = tuple([c for c in xx[start: start + gram_size] if c is not None])\n",
    "                if xgram and xgram in self.replaced_tuples:\n",
    "                    found_grams.append((xgram, self.replaced_tuples[xgram], len(xgram)))\n",
    "        found_grams = sorted(found_grams, key=lambda x: (x[2], x[1]), reverse=True)\n",
    "        \n",
    "        results = []\n",
    "        for i in range(n_out or 1):\n",
    "            untext = ' '.join([''] + xx + [''])\n",
    "            for gram, gn, gl in found_grams:\n",
    "                gram_text = ' '.join([''] + list(gram) + [''])\n",
    "                reps, ww = zip(*self.replace_proba[gram_text])\n",
    "                if not temperature:\n",
    "                    chosen_rep = list(reps)[np.argmax(ww)]\n",
    "                else: # chose randomly\n",
    "                    weights = [w ** (1 / temperature) for w in ww]\n",
    "                    chosen_rep = random.choices(list(reps), weights=weights)[0]\n",
    "                untext = untext.replace(gram_text, chosen_rep)\n",
    "            results.append(self.detokenize(untext))\n",
    "        if not n_out:\n",
    "            return results[0]\n",
    "        return results\n",
    "    \n",
    "    def transform(self, texts, n_out=None, temperature=None):\n",
    "        return [self.transform_one(text, n_out=n_out, temperature=temperature) for text in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bf3e83fdc14f74bab64a80dd5d8f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TextReplacer at 0x7f817049d510>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer = TextReplacer(min_n=3)\n",
    "replacer.fit(train.toxic_ru.tolist(), train.neutral_ru.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Почему тут делает этот?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer.transform_one(\"Какого хуя тут делает этот придурок?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8016dda94134e62b5babaf72d2db8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "60.245284369211014"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrfpp.corpus_score(replacer.transform(val.toxic_ru), [val.neutral_ru.tolist()]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare test methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase(\n",
    "    text, model, tokenizer, n=None, max_length=\"auto\", beams=5,\n",
    "):\n",
    "    texts = [text] if isinstance(text, str) else text\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True)[\"input_ids\"].to(\n",
    "        model.device\n",
    "    )\n",
    "\n",
    "    if max_length == \"auto\":\n",
    "        max_length = inputs.shape[1] + 10\n",
    "\n",
    "    result = model.generate(\n",
    "        inputs,\n",
    "        num_return_sequences=n or 1,\n",
    "        do_sample=False,\n",
    "        temperature=1.0,\n",
    "        repetition_penalty=10.0,\n",
    "        max_length=max_length,\n",
    "        min_length=int(0.5 * max_length),\n",
    "        num_beams=beams,\n",
    "        #forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
    "    )\n",
    "    texts = [tokenizer.decode(r, skip_special_tokens=True) for r in result]\n",
    "\n",
    "    if not n and isinstance(text, str):\n",
    "        return texts[0]\n",
    "    return texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/russian_data/test.tsv', sep='\\t')\n",
    "test_inputs = test_data[\"toxic_comment\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune ruT5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# base_model = 'google/mt5-base'\n",
    "base_model = 'sberbank-ai/ruT5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(base_model).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, padding=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"target\"], padding=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2412854bf3294058a4c76d7dc1328299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710b064612a64cd58145fa3315236700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9ee81f47cc407285293ad0a6e50427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4ef158ca23417aac95404657a9ccf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_data = raw_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/home/dale/models/detox-parallel/translate-en2ru-full-rut5\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=1e-5,\n",
    "    max_steps=10_000,\n",
    "    learning_rate=1e-5,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=1,\n",
    "    eval_steps=500, \n",
    "    save_steps=500,\n",
    "    logging_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_data[\"train\"],\n",
    "    eval_dataset=tok_data[\"dev\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 17739\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 26:51, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.791000</td>\n",
       "      <td>0.529552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.630500</td>\n",
       "      <td>0.489399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.574000</td>\n",
       "      <td>0.463955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.553800</td>\n",
       "      <td>0.459029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.524600</td>\n",
       "      <td>0.451687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.511300</td>\n",
       "      <td>0.443014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.501200</td>\n",
       "      <td>0.440186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.494100</td>\n",
       "      <td>0.432363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.487100</td>\n",
       "      <td>0.432016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.471300</td>\n",
       "      <td>0.429997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.466400</td>\n",
       "      <td>0.428239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.469500</td>\n",
       "      <td>0.427046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.467900</td>\n",
       "      <td>0.422794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.469700</td>\n",
       "      <td>0.425346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.454300</td>\n",
       "      <td>0.420907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.451200</td>\n",
       "      <td>0.422169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>0.421177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.421767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.450800</td>\n",
       "      <td>0.421191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.443700</td>\n",
       "      <td>0.420855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-500/spiece.model\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-3500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-4500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-5500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7000/spiece.model\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-6500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8000/spiece.model\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-8500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-10000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-10000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-10000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-10000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-7500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-9500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/dale/models/detox-parallel/translate-en2ru-full-rut5/checkpoint-10000 (score: 0.4208545386791229).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=0.555692317199707, metrics={'train_runtime': 1611.2303, 'train_samples_per_second': 49.652, 'train_steps_per_second': 6.206, 'total_flos': 7229199591060480.0, 'train_loss': 0.555692317199707, 'epoch': 4.51})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484d492f300747deb474e962aad6e233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.69545289600716\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "model.eval()\n",
    "for text in tqdm(val.toxic_ru):\n",
    "    with torch.inference_mode():\n",
    "        out = tokenizer.decode(\n",
    "            model.generate(**tokenizer(text, return_tensors='pt').to(model.device), num_beams=5, max_length=256)[0], \n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "        preds.append(out)\n",
    "        \n",
    "print(chrfpp.corpus_score(preds, [val.neutral_ru.tolist()]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4890     Да, я вернулся в этот уединенный зад, мир субт...\n",
       "2153                           Два дурака не делают права.\n",
       "18757           Это дерьмо должно прекратиться, сейчас же!\n",
       "16963    Да, посмотри на всех китайских иммигрантов и и...\n",
       "17502    Подумай больше, будь скучной маленькой сучкой ...\n",
       "Name: toxic_ru, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.toxic_ru[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Да, я вернулся в этот уединенный мир субтитрах и безлежащих лол.',\n",
       " 'Два человека не делают права.',\n",
       " 'Это должно прекратиться сейчас же.',\n",
       " 'Да, посмотри на всех китайских иммигрантов и иммигрантов, которые делают одно и то же.',\n",
       " 'Подумай больше, будь скучной маленькой девочкой меньше.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = [paraphrase(text, model, tokenizer) for text in tqdm(test_inputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/translate-train-full/results_ru.txt', 'w') as f:\n",
    "    for text in test_outputs:\n",
    "        f.write(text+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune with filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/sberbank-ai/ruT5-base/resolve/main/config.json from cache at /home/dale/.cache/huggingface/transformers/15f5f9138b337892ef8dadfab622952847d6eb4b5985a825847fbaa18538bae9.d9b947fcfcea30df5eb71effa3afe0a2e3da3535463b97a14c3c0401ac680b99\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/ruT5-base\",\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/sberbank-ai/ruT5-base/resolve/main/pytorch_model.bin from cache at /home/dale/.cache/huggingface/transformers/980364cd851d2f2c4b3162d3a75f2619467ecf488abcb768d95963eb5243a550.27717171a12f478b1ad9a147e06c7572baddd04afa54b6ce25c9e71ff869e365\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at sberbank-ai/ruT5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/sberbank-ai/ruT5-base/resolve/main/config.json from cache at /home/dale/.cache/huggingface/transformers/15f5f9138b337892ef8dadfab622952847d6eb4b5985a825847fbaa18538bae9.d9b947fcfcea30df5eb71effa3afe0a2e3da3535463b97a14c3c0401ac680b99\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/ruT5-base\",\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/sberbank-ai/ruT5-base/resolve/main/spiece.model from cache at /home/dale/.cache/huggingface/transformers/8fbfe82cf1b77f4ac04613497162d96b2f7c8ab4a25bd300966efbbad1538b08.de6bf5908caf6fd63249e0b4bd24b2456d5575ca9032ee501e81053a3be7cb62\n",
      "loading file https://huggingface.co/sberbank-ai/ruT5-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/sberbank-ai/ruT5-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/sberbank-ai/ruT5-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/sberbank-ai/ruT5-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/sberbank-ai/ruT5-base/resolve/main/config.json from cache at /home/dale/.cache/huggingface/transformers/15f5f9138b337892ef8dadfab622952847d6eb4b5985a825847fbaa18538bae9.d9b947fcfcea30df5eb71effa3afe0a2e3da3535463b97a14c3c0401ac680b99\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/ruT5-base\",\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/sberbank-ai/ruT5-base/resolve/main/config.json from cache at /home/dale/.cache/huggingface/transformers/15f5f9138b337892ef8dadfab622952847d6eb4b5985a825847fbaa18538bae9.d9b947fcfcea30df5eb71effa3afe0a2e3da3535463b97a14c3c0401ac680b99\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/ruT5-base\",\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(base_model).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=1e-5,\n",
    "    max_steps=10_000,\n",
    "    learning_rate=1e-5,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=1,\n",
    "    eval_steps=500, \n",
    "    save_steps=500,\n",
    "    logging_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_data[\"train_75\"],\n",
    "    eval_dataset=tok_data[\"dev\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 13304\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 22:48, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.749800</td>\n",
       "      <td>0.529447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>0.487823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.561700</td>\n",
       "      <td>0.474613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.541200</td>\n",
       "      <td>0.460573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>0.454732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.505900</td>\n",
       "      <td>0.448597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.480400</td>\n",
       "      <td>0.446434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.469600</td>\n",
       "      <td>0.441509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.474900</td>\n",
       "      <td>0.440623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.466500</td>\n",
       "      <td>0.435725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.452300</td>\n",
       "      <td>0.436739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.449800</td>\n",
       "      <td>0.433393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.436600</td>\n",
       "      <td>0.430748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.441100</td>\n",
       "      <td>0.429341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.442500</td>\n",
       "      <td>0.428678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>0.428665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.427669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>0.427597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.420500</td>\n",
       "      <td>0.428253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.427946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-500/spiece.model\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-3500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-4500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5500/spiece.model\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-5500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-6500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-7500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8500/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-8500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9500/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9500/spiece.model\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-10000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-10000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-10000/special_tokens_map.json\n",
      "Copy vocab file to /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-10000/spiece.model\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/dale/models/detox-parallel/translate-en2ru-filter75best-rut5/checkpoint-9000 (score: 0.4275968670845032).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=0.537236734008789, metrics={'train_runtime': 1369.1657, 'train_samples_per_second': 58.43, 'train_steps_per_second': 7.304, 'total_flos': 5148767509585920.0, 'train_loss': 0.537236734008789, 'epoch': 6.01})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99dcea3d040c4434bc4ccf6c8c959c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_outputs = [paraphrase(text, model, tokenizer) for text in tqdm(test_inputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../results/translate-train-full/results_ru.txt', 'w') as f:\n",
    "with open('../results/translate-train-filter75best/results_ru.txt', 'w') as f:\n",
    "    for text in test_outputs:\n",
    "        f.write(text+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune mBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'facebook/mbart-large-50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(base_model)# .cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, padding=True)\n",
    "    labels = tokenizer(examples[\"target\"], padding=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784c7ea33a8e48f98d067d25b9010b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f978923411ae4d67bdc258cb798e67d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d5d886f3f549d1859a8fe2803a1889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e306a304841487789d3293f75700fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_data = raw_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/home/dale/models/detox-parallel/translate-en2ru-full-mbart\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=1, # 8 is too much \n",
    "    weight_decay=1e-5,\n",
    "    max_steps=10_000,\n",
    "    learning_rate=1e-5,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=1,\n",
    "    eval_steps=500, \n",
    "    save_steps=500,\n",
    "    logging_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    # trying to save memory: see https://huggingface.co/docs/transformers/performance\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adafactor\",\n",
    "    gradient_accumulation_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_data[\"train\"],\n",
    "    eval_dataset=tok_data[\"dev\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 17739\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 1:05:18, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.427477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>0.404340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.435100</td>\n",
       "      <td>0.388027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.423300</td>\n",
       "      <td>0.380501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>0.378985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.339700</td>\n",
       "      <td>0.374920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.369522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.333100</td>\n",
       "      <td>0.361089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.369869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.269400</td>\n",
       "      <td>0.377038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.367969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.361572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.274300</td>\n",
       "      <td>0.363423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.249500</td>\n",
       "      <td>0.377036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.230200</td>\n",
       "      <td>0.378078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.377742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.373168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.382414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>0.385595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.384388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-500/special_tokens_map.json\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-500] due to args.save_total_limit\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1000] due to args.save_total_limit\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-1500] due to args.save_total_limit\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-3500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5000] due to args.save_total_limit\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-5500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-6500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-7500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-8500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9000] due to args.save_total_limit\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: text, target. If text, target are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-10000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-10000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-9500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/dale/models/detox-parallel/translate-en2ru-full-mbart/checkpoint-4000 (score: 0.36108896136283875).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=0.3072514045715332, metrics={'train_runtime': 3919.3933, 'train_samples_per_second': 20.411, 'train_steps_per_second': 2.551, 'total_flos': 1.0544019625918464e+16, 'train_loss': 0.3072514045715332, 'epoch': 4.51})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a99381a6d9462d93747a71449f42ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.30470213875236\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "model.eval()\n",
    "for text in tqdm(val.toxic_ru):\n",
    "    with torch.inference_mode():\n",
    "        out = tokenizer.decode(\n",
    "            model.generate(**tokenizer(text, return_tensors='pt').to(model.device), num_beams=5, max_length=256)[0], \n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "        preds.append(out)\n",
    "        \n",
    "print(chrfpp.corpus_score(preds, [val.neutral_ru.tolist()]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4890     Да, я вернулся в этот уединенный зад, мир субт...\n",
       "2153                           Два дурака не делают права.\n",
       "18757           Это дерьмо должно прекратиться, сейчас же!\n",
       "16963    Да, посмотри на всех китайских иммигрантов и и...\n",
       "17502    Подумай больше, будь скучной маленькой сучкой ...\n",
       "Name: toxic_ru, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.toxic_ru[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Да, я вернулся в этот уединенный мир субтитров и безлежащих лол',\n",
       " 'Два человека не делают права.',\n",
       " 'Это должно прекратиться, сейчас же!',\n",
       " 'Да, посмотри на всех китайских иммигрантов и иммигрантов-задниц, которые делают одно и то же',\n",
       " 'Подумай больше, будь скучной.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a13c13c3754a6fbc49a4e93a6b2e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_outputs = [paraphrase(text, model, tokenizer) for text in tqdm(test_inputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/translate-train-full-mbart/results_ru.txt', 'w') as f:\n",
    "    for text in test_outputs:\n",
    "        f.write(text+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune mBART with BOTH English (original) and Russian (translated) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 35478\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = DatasetDict({\n",
    "    'train': Dataset.from_dict({\n",
    "        'text': train.toxic_ru.tolist() + train.toxic_comment.tolist(), \n",
    "        'target': train.neutral_ru.tolist() + train.neutral_comment.tolist()}),\n",
    "    'dev': Dataset.from_dict({'text': val.toxic_ru, 'target': val.neutral_ru}),\n",
    "})\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'facebook/mbart-large-50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(base_model)# .cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, padding=True)\n",
    "    labels = tokenizer(examples[\"target\"], padding=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1994fb1d344a7f9cca65f6cdc9c87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeb8411c22c4d43b59df23ed314f0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_data = raw_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=1, # 8 is too much \n",
    "    weight_decay=1e-5,\n",
    "    max_steps=10_000,\n",
    "    learning_rate=1e-5,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=1,\n",
    "    eval_steps=500, \n",
    "    save_steps=500,\n",
    "    logging_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    # trying to save memory: see https://huggingface.co/docs/transformers/performance\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adafactor\",\n",
    "    gradient_accumulation_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_data[\"train\"],\n",
    "    eval_dataset=tok_data[\"dev\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 35478\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10000\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6407' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6407/10000 40:39 < 22:48, 2.63 it/s, Epoch 1.44/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.753400</td>\n",
       "      <td>0.483804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.488500</td>\n",
       "      <td>0.427407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.430500</td>\n",
       "      <td>0.413124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.426700</td>\n",
       "      <td>0.400756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.419600</td>\n",
       "      <td>0.400767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.410500</td>\n",
       "      <td>0.387422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.402500</td>\n",
       "      <td>0.379763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.389400</td>\n",
       "      <td>0.376156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>0.374747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.325200</td>\n",
       "      <td>0.372850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.334500</td>\n",
       "      <td>0.371136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.322700</td>\n",
       "      <td>0.369873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "model.eval()\n",
    "for text in tqdm(val.toxic_ru):\n",
    "    with torch.inference_mode():\n",
    "        out = tokenizer.decode(\n",
    "            model.generate(**tokenizer(text, return_tensors='pt').to(model.device), num_beams=5, max_length=256)[0], \n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "        preds.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.41759247020497\n"
     ]
    }
   ],
   "source": [
    "print(chrfpp.corpus_score(preds, [val.neutral_ru.tolist()]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4890     Да, я вернулся в этот уединенный зад, мир субт...\n",
       "2153                           Два дурака не делают права.\n",
       "18757           Это дерьмо должно прекратиться, сейчас же!\n",
       "16963    Да, посмотри на всех китайских иммигрантов и и...\n",
       "17502    Подумай больше, будь скучной маленькой сучкой ...\n",
       "Name: toxic_ru, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.toxic_ru[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Да, я вернулся в этот уединенный мир субтитра и безлежащих лол',\n",
       " 'Два человека не делают права.',\n",
       " 'Это должно прекратиться, сейчас же!',\n",
       " 'Да, посмотри на всех китайских иммигрантов и иммигрантов, которые делают одно и то же.',\n",
       " 'Подумай больше, будь скучной.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f195c52a854a5c902234cd026eee1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_outputs = [paraphrase(text, model, tokenizer) for text in tqdm(test_inputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/translate-train-full_bilingual-mbart/results_ru.txt', 'w') as f:\n",
    "    for text in test_outputs:\n",
    "        f.write(text+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the 25% worst text pairs results in a slight increase in meaning and style scores. \n",
    "\n",
    "However, we do not know whether it really translates into better quality, or it is just overfitting to the metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python evaluate_ru.py \\\n",
    "    --result_filename scores \\\n",
    "    --input_dir results/translate-train-full \\\n",
    "    --output_dir results\n",
    "```\n",
    "\n",
    "```\n",
    "Style accuracy:       0.4402829706668854\n",
    "Meaning preservation: 0.8662738800048828\n",
    "Joint fluency:        -0.1310407668352127\n",
    "Joint score:          -0.04819316789507866\n",
    "Scores after calibration:\n",
    "Style accuracy:       0.49625468254089355\n",
    "Meaning preservation: 0.7994107604026794\n",
    "Joint fluency:        0.849303126335144\n",
    "Joint score:          0.3282524347305298\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python evaluate_ru.py \\\n",
    "    --result_filename scores \\\n",
    "    --input_dir results/translate-train-filter75best \\\n",
    "    --output_dir results\n",
    "```\n",
    "\n",
    "```\n",
    "Style accuracy:       0.46567192673683167\n",
    "Meaning preservation: 0.8696921467781067\n",
    "Joint fluency:        -0.1312914490699768\n",
    "Joint score:          -0.05280234292149544\n",
    "Scores after calibration:\n",
    "Style accuracy:       0.5191047191619873\n",
    "Meaning preservation: 0.8045381903648376\n",
    "Joint fluency:        0.8490148782730103\n",
    "Joint score:          0.3441106677055359\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mBART is more fluent than RuT5!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python evaluate_ru.py \\\n",
    "    --result_filename scores \\\n",
    "    --input_dir results/translate-train-full-mbart \\\n",
    "    --output_dir results\n",
    "    \n",
    "Style accuracy:       0.4556241035461426\n",
    "Meaning preservation: 0.8801424503326416\n",
    "Joint fluency:        -0.10965493321418762\n",
    "Joint score:          -0.04347466304898262\n",
    "Scores after calibration:\n",
    "Style accuracy:       0.5100616812705994\n",
    "Meaning preservation: 0.8203034400939941\n",
    "Joint fluency:        0.8738968372344971\n",
    "Joint score:          0.35575705766677856\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python evaluate_ru.py \\\n",
    "    --result_filename scores \\\n",
    "    --input_dir results/translate-train-full_bilingual-mbart \\\n",
    "    --output_dir results\n",
    "    \n",
    "Style accuracy:       0.5142309665679932\n",
    "Meaning preservation: 0.8898885250091553\n",
    "Joint fluency:        -0.08569465577602386\n",
    "Joint score:          -0.04080545902252197\n",
    "Scores after calibration:\n",
    "Style accuracy:       0.5628078579902649\n",
    "Meaning preservation: 0.8349745273590088\n",
    "Joint fluency:        0.9014511704444885\n",
    "Joint score:          0.41200950741767883\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3k",
   "language": "python",
   "name": "p3k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
