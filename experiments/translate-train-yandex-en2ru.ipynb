{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Translate the English training set into Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detox_en_train = pd.read_csv('../data/english_data/en_data.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19766, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>toxic_comment</th>\n",
       "      <th>neutral_comment</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>toxic</th>\n",
       "      <th>confidence_toxic</th>\n",
       "      <th>is_match</th>\n",
       "      <th>confidence_is_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14308</th>\n",
       "      <td>162672</td>\n",
       "      <td>read the headline and my only reaction was , \" fuck , again ? ? ? ? \"</td>\n",
       "      <td>Read the headline and my only reaction was. Again???</td>\n",
       "      <td>0.997740</td>\n",
       "      <td>reddit</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7850</th>\n",
       "      <td>41551</td>\n",
       "      <td>that shit irritates me with a passion lol</td>\n",
       "      <td>That irritate me</td>\n",
       "      <td>0.998720</td>\n",
       "      <td>twitter</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>21636</td>\n",
       "      <td>put alot of that green shit on</td>\n",
       "      <td>put alot of that green stuff on</td>\n",
       "      <td>0.998061</td>\n",
       "      <td>twitter</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>44090</td>\n",
       "      <td>those cunts need sorting out !</td>\n",
       "      <td>Those guys need to sort out.</td>\n",
       "      <td>0.997767</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10080</th>\n",
       "      <td>44179</td>\n",
       "      <td>i suppose it 's more fun to make shit up</td>\n",
       "      <td>i suppose it 's more fun to make things up.</td>\n",
       "      <td>0.986727</td>\n",
       "      <td>twitter</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx  \\\n",
       "14308  162672   \n",
       "7850    41551   \n",
       "8728    21636   \n",
       "3410    44090   \n",
       "10080   44179   \n",
       "\n",
       "                                                               toxic_comment  \\\n",
       "14308  read the headline and my only reaction was , \" fuck , again ? ? ? ? \"   \n",
       "7850                               that shit irritates me with a passion lol   \n",
       "8728                                          put alot of that green shit on   \n",
       "3410                                          those cunts need sorting out !   \n",
       "10080                               i suppose it 's more fun to make shit up   \n",
       "\n",
       "                                            neutral_comment  toxicity_score  \\\n",
       "14308  Read the headline and my only reaction was. Again???        0.997740   \n",
       "7850                                       That irritate me        0.998720   \n",
       "8728                        put alot of that green stuff on        0.998061   \n",
       "3410                           Those guys need to sort out.        0.997767   \n",
       "10080           i suppose it 's more fun to make things up.        0.986727   \n",
       "\n",
       "       dataset  toxic  confidence_toxic  is_match  confidence_is_match  \n",
       "14308   reddit  False            0.9987      True               0.9679  \n",
       "7850   twitter  False            0.9972      True               0.9777  \n",
       "8728   twitter  False            0.9987      True               0.9906  \n",
       "3410    jigsaw  False            0.9994      True               0.9230  \n",
       "10080  twitter  False            0.9914      True               0.9924  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dale/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_by_symbol(text, symbol=',', max_len=400):\n",
    "    if len(text) <= max_len:\n",
    "        return [text]\n",
    "    chunks = re.split(symbol, text)\n",
    "    if len(chunks) <= 1:\n",
    "        return [text]\n",
    "    result = [chunks[0]]\n",
    "    for chunk in chunks[1:]:\n",
    "        result.append(symbol)\n",
    "        result.append(chunk)\n",
    "    return result\n",
    "\n",
    "def join_texts(texts, max_len=400):\n",
    "    result = []\n",
    "    prev_text = ''\n",
    "    for text in texts:\n",
    "        if len(text) + len(prev_text) > max_len:\n",
    "            result.append(prev_text)\n",
    "            prev_text = text\n",
    "        else:\n",
    "            prev_text = prev_text + text\n",
    "    result.append(prev_text)\n",
    "    return result\n",
    "\n",
    "def hard_split(text, max_len=300):\n",
    "    parts = list(sent_tokenize(text))\n",
    "    result = []\n",
    "    for part in parts:\n",
    "        chunks = [part]\n",
    "        for symbol in [',', '-', ' ']:\n",
    "            chunks = [c2 for c in chunks for c2 in split_by_symbol(c, symbol, max_len=max_len)]\n",
    "        result.extend(chunks)\n",
    "    result = join_texts(result, max_len=max_len)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "How to obtain a fresh SID:\n",
    "* go to translate.yandex.ru\n",
    "* open the \"network\" panel of the developers console\n",
    "* enter any text in the translation form\n",
    "* find the request to \"https://translate.yandex.net/api/v1/tr.json/translate\" and copy its first parameter (\"id\")\n",
    "'''\n",
    "\n",
    "import requests\n",
    "\n",
    "SID = '7d9e19fd.62960895.db4a787d.74722d74657874-8-0'\n",
    "\n",
    "def translate_yandex(search_str, direction='en-ru', full_response=False):\n",
    "    try:\n",
    "        url = f'https://translate.yandex.net/api/v1/tr.json/translate?id={SID}&srv=tr-text&lang={direction}&reason=auto&format=text'\n",
    "\n",
    "        post_header = {}\n",
    "        post_header['Accept'] = '*/*'\n",
    "        post_header['Accept-Encoding'] = 'gzip, deflate'\n",
    "        post_header['Accept-Language'] = 'en-US,en;q=0.9'\n",
    "        post_header['Cache-Control'] = 'no-cache'\n",
    "        post_header['Connection'] = 'keep-alive'\n",
    "        post_header['Content-Type'] = 'application/x-www-form-urlencoded'\n",
    "        post_header['Host'] = 'translate.yandex.com'\n",
    "        post_header['Referer'] = 'https://translate.yandex.com/'\n",
    "        post_header['User-Agent'] = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 YaBrowser/21.8.2.383 Yowser/2.5 Safari/537.36'\n",
    "\n",
    "\n",
    "        data_payload = {'text': search_str, 'options': '4'}\n",
    "\n",
    "        resp = requests.post(url, headers=post_header, data=data_payload).json()\n",
    "        #print(resp)\n",
    "        if full_response:\n",
    "            return resp\n",
    "\n",
    "        if resp.get('message') == 'The text size exceeds the maximum':\n",
    "            parts = hard_split(search_str)\n",
    "            if len(parts) > 1:\n",
    "                return 200, ' '.join([translate_yandex(part, dir=dir)[1] for part in parts])\n",
    "\n",
    "        return resp['code'], resp['text'][0]\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        return 0, ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 'иди к черту')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_yandex('go to hell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he had steel balls too !',\n",
       " 'dude should have been taken to api , he would be right at home with all the other knuckleheads there',\n",
       " 'im not gonna sell the fucking picture , i just want to contribute to the fucking article .',\n",
       " 'the garbage that is being created by cnn and other news agencies is outrageous .',\n",
       " 'the reason they dont exist is because neither is a pathological liar like trump .']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.toxic_comment[:5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['у него тоже были стальные яйца!',\n",
       " 'чувака надо было отвезти в апи, он был бы там как дома со всеми остальными болванами',\n",
       " 'я не собираюсь продавать эту гребаную фотографию, я просто хочу внести свой вклад в гребаную статью.',\n",
       " 'мусор, который создают cnn и другие информационные агентства, возмутителен.',\n",
       " 'причина, по которой их не существует, заключается в том, что ни один из них не является таким патологическим лжецом, как Трамп.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[translate_yandex(t)[1] for t in detox_en_train.toxic_comment[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['он тоже был храбрым!',\n",
       " 'Было бы хорошо, если бы он пошел в апи. Он бы вписался.',\n",
       " 'Я не собираюсь продавать фотографию, я просто хочу внести свой вклад в статью.',\n",
       " 'новости, которые создают cnn и другие информационные агентства, возмутительны.',\n",
       " 'Причина, по которой их не существует, заключается в том, что ни один из них не лжет так, как Трамп']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[translate_yandex(t)[1] for t in detox_en_train.neutral_comment[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1929cfeefe0644fe874663c275022bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19766 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxic_ru = []\n",
    "neutral_ru = []\n",
    "for i in trange(0, len(detox_en_train)):\n",
    "    toxic_ru.append(translate_yandex(detox_en_train.toxic_comment[i])[1])\n",
    "    neutral_ru.append(translate_yandex(detox_en_train.neutral_comment[i])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "detox_en_train['toxic_ru'] = toxic_ru\n",
    "detox_en_train['neutral_ru'] = neutral_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>toxic_comment</th>\n",
       "      <th>neutral_comment</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>toxic</th>\n",
       "      <th>confidence_toxic</th>\n",
       "      <th>is_match</th>\n",
       "      <th>confidence_is_match</th>\n",
       "      <th>toxic_ru</th>\n",
       "      <th>neutral_ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15032</th>\n",
       "      <td>119985</td>\n",
       "      <td>are you implying the cops are pussies - - thus they fired out of legitimate fear for their safety ?</td>\n",
       "      <td>Are you implying the cops are cowards - thus, they fired out of legitimate fear for their own safety?</td>\n",
       "      <td>0.996316</td>\n",
       "      <td>reddit</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>вы намекаете на то, что копы - слабаки, и поэтому они стреляли из законного страха за свою безопасность?</td>\n",
       "      <td>Вы намекаете на то, что копы трусы - таким образом, они стреляли из законного страха за свою собственную безопасность?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607</th>\n",
       "      <td>151094</td>\n",
       "      <td>yea something like \" surgeon general said that an apple a day or some shit</td>\n",
       "      <td>yea something like \" surgeon general said that an apple a day or something</td>\n",
       "      <td>0.994066</td>\n",
       "      <td>reddit</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>да, что-то вроде \"главный хирург сказал, что яблоко в день или что-то в этом роде</td>\n",
       "      <td>да, что-то вроде \"главный хирург сказал, что яблоко в день или что-то в этом роде</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>77029</td>\n",
       "      <td>the only logical conclusion i see here is that trump is a lying sack .</td>\n",
       "      <td>The only logical conclusion I can draw from this is that Trump is a lied</td>\n",
       "      <td>0.997076</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9564</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>единственный логический вывод, который я вижу здесь, заключается в том, что Трамп - лживый мешок.</td>\n",
       "      <td>Единственный логический вывод, который я могу сделать из этого, заключается в том, что Трамп - лжец</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>35987</td>\n",
       "      <td>what kind of rat hole do these monsters come from ?</td>\n",
       "      <td>what kind of a hole these came from</td>\n",
       "      <td>0.993900</td>\n",
       "      <td>jigsaw</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>из какой крысиной норы появляются эти монстры?</td>\n",
       "      <td>из какой дыры они взялись</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6652</th>\n",
       "      <td>3542</td>\n",
       "      <td>man this shit is gettin wiild over here lol .</td>\n",
       "      <td>man this is gettin wiild over here lol .</td>\n",
       "      <td>0.996682</td>\n",
       "      <td>twitter</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>чувак, это дерьмо становится все более распространенным, лол.</td>\n",
       "      <td>блин, это уже начинает надоедать, лол.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx  \\\n",
       "15032  119985   \n",
       "14607  151094   \n",
       "3781    77029   \n",
       "1002    35987   \n",
       "6652     3542   \n",
       "\n",
       "                                                                                             toxic_comment  \\\n",
       "15032  are you implying the cops are pussies - - thus they fired out of legitimate fear for their safety ?   \n",
       "14607                           yea something like \" surgeon general said that an apple a day or some shit   \n",
       "3781                                the only logical conclusion i see here is that trump is a lying sack .   \n",
       "1002                                                   what kind of rat hole do these monsters come from ?   \n",
       "6652                                                         man this shit is gettin wiild over here lol .   \n",
       "\n",
       "                                                                                             neutral_comment  \\\n",
       "15032  Are you implying the cops are cowards - thus, they fired out of legitimate fear for their own safety?   \n",
       "14607                             yea something like \" surgeon general said that an apple a day or something   \n",
       "3781                                The only logical conclusion I can draw from this is that Trump is a lied   \n",
       "1002                                                                     what kind of a hole these came from   \n",
       "6652                                                                man this is gettin wiild over here lol .   \n",
       "\n",
       "       toxicity_score  dataset  toxic  confidence_toxic  is_match  \\\n",
       "15032        0.996316   reddit  False            0.9824      True   \n",
       "14607        0.994066   reddit  False            0.9955      True   \n",
       "3781         0.997076   jigsaw  False            0.9564      True   \n",
       "1002         0.993900   jigsaw  False            0.9990      True   \n",
       "6652         0.996682  twitter  False            0.9957      True   \n",
       "\n",
       "       confidence_is_match  \\\n",
       "15032               0.9482   \n",
       "14607               0.9757   \n",
       "3781                0.9834   \n",
       "1002                0.9451   \n",
       "6652                0.9924   \n",
       "\n",
       "                                                                                                       toxic_ru  \\\n",
       "15032  вы намекаете на то, что копы - слабаки, и поэтому они стреляли из законного страха за свою безопасность?   \n",
       "14607                         да, что-то вроде \"главный хирург сказал, что яблоко в день или что-то в этом роде   \n",
       "3781          единственный логический вывод, который я вижу здесь, заключается в том, что Трамп - лживый мешок.   \n",
       "1002                                                             из какой крысиной норы появляются эти монстры?   \n",
       "6652                                              чувак, это дерьмо становится все более распространенным, лол.   \n",
       "\n",
       "                                                                                                                   neutral_ru  \n",
       "15032  Вы намекаете на то, что копы трусы - таким образом, они стреляли из законного страха за свою собственную безопасность?  \n",
       "14607                                       да, что-то вроде \"главный хирург сказал, что яблоко в день или что-то в этом роде  \n",
       "3781                      Единственный логический вывод, который я могу сделать из этого, заключается в том, что Трамп - лжец  \n",
       "1002                                                                                                из какой дыры они взялись  \n",
       "6652                                                                                   блин, это уже начинает надоедать, лол.  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "detox_en_train.to_csv('detox_en2ru_yandex.tsv', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011079631690782151"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(detox_en_train.toxic_ru == detox_en_train.neutral_ru).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19766.000000\n",
       "mean        60.839269\n",
       "std         24.365534\n",
       "min          8.000000\n",
       "25%         41.000000\n",
       "50%         57.000000\n",
       "75%         77.000000\n",
       "max        173.000000\n",
       "Name: toxic_ru, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.toxic_ru.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19766.000000\n",
       "mean        51.011889\n",
       "std         24.548076\n",
       "min          1.000000\n",
       "25%         32.000000\n",
       "50%         47.000000\n",
       "75%         67.000000\n",
       "max        165.000000\n",
       "Name: neutral_ru, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.neutral_ru.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textdistance import levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "detox_en_train['edit_distance_en'] = [levenshtein.distance(*row) for row in detox_en_train[['toxic_comment', 'neutral_comment']].values]\n",
    "detox_en_train['edit_distance_ru'] = [levenshtein.distance(*row) for row in detox_en_train[['toxic_ru', 'neutral_ru']].values]\n",
    "\n",
    "detox_en_train['edit_sim_en'] = [levenshtein.normalized_similarity(*row) for row in detox_en_train[['toxic_comment', 'neutral_comment']].values]\n",
    "detox_en_train['edit_sim_ru'] = [levenshtein.normalized_similarity(*row) for row in detox_en_train[['toxic_ru', 'neutral_ru']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>toxicity_score</th>\n",
       "      <th>confidence_toxic</th>\n",
       "      <th>confidence_is_match</th>\n",
       "      <th>edit_distance_en</th>\n",
       "      <th>edit_distance_ru</th>\n",
       "      <th>edit_sim_en</th>\n",
       "      <th>edit_sim_ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "      <td>19766.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78035.783416</td>\n",
       "      <td>0.990181</td>\n",
       "      <td>0.984174</td>\n",
       "      <td>0.972585</td>\n",
       "      <td>15.705757</td>\n",
       "      <td>22.234139</td>\n",
       "      <td>0.696492</td>\n",
       "      <td>0.618786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>60839.351686</td>\n",
       "      <td>0.019532</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>0.025094</td>\n",
       "      <td>10.989535</td>\n",
       "      <td>13.887489</td>\n",
       "      <td>0.186762</td>\n",
       "      <td>0.200999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.800983</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31839.000000</td>\n",
       "      <td>0.991065</td>\n",
       "      <td>0.981100</td>\n",
       "      <td>0.961100</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>63895.000000</td>\n",
       "      <td>0.996133</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>0.980500</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.649123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101255.250000</td>\n",
       "      <td>0.998179</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.991100</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.776316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>238836.000000</td>\n",
       "      <td>0.999647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 idx  toxicity_score  confidence_toxic  confidence_is_match  \\\n",
       "count   19766.000000    19766.000000      19766.000000         19766.000000   \n",
       "mean    78035.783416        0.990181          0.984174             0.972585   \n",
       "std     60839.351686        0.019532          0.025847             0.025094   \n",
       "min         7.000000        0.800983          0.523700             0.800000   \n",
       "25%     31839.000000        0.991065          0.981100             0.961100   \n",
       "50%     63895.000000        0.996133          0.994100             0.980500   \n",
       "75%    101255.250000        0.998179          0.998500             0.991100   \n",
       "max    238836.000000        0.999647          1.000000             0.999900   \n",
       "\n",
       "       edit_distance_en  edit_distance_ru   edit_sim_en   edit_sim_ru  \n",
       "count      19766.000000      19766.000000  19766.000000  19766.000000  \n",
       "mean          15.705757         22.234139      0.696492      0.618786  \n",
       "std           10.989535         13.887489      0.186762      0.200999  \n",
       "min            0.000000          0.000000      0.000000      0.000000  \n",
       "25%            8.000000         12.000000      0.590909      0.480000  \n",
       "50%           12.000000         19.000000      0.741935      0.649123  \n",
       "75%           20.000000         29.000000      0.838710      0.776316  \n",
       "max          105.000000        129.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edit_distance_en</th>\n",
       "      <th>edit_sim_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.99</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      edit_distance_en  edit_sim_en\n",
       "0.01               3.0     0.192308\n",
       "0.05               5.0     0.312500\n",
       "0.90              30.0     0.900000\n",
       "0.99              56.0     0.961538"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detox_en_train[['edit_distance_en', 'edit_sim_en']].quantile([0.01, 0.05, 0.90, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017150662754224427\n",
      "0.027774967115248406\n",
      "0.021552160275220073\n",
      "0.015987048467064658\n"
     ]
    }
   ],
   "source": [
    "# detox_en_train[['edit_distance_en', 'edit_sim_en']].quantile([0.01, 0.05, 0.90, 0.99])\n",
    "print((detox_en_train.edit_distance_ru < 3).mean())\n",
    "print((detox_en_train.edit_distance_ru > 56).mean())\n",
    "\n",
    "print((detox_en_train.edit_sim_ru < 0.19).mean())\n",
    "print((detox_en_train.edit_sim_ru > 0.96).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the Russian model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "detox_en2ru = pd.read_csv('detox_en2ru_yandex.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter text pairs by similarity to escape translation artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19766, 15)\n",
      "(18488, 15)\n"
     ]
    }
   ],
   "source": [
    "detox_en2ru_filtered = detox_en2ru[\n",
    "    (detox_en2ru.edit_distance_ru >= detox_en2ru.edit_distance_en.quantile(0.01)) \n",
    "    & (detox_en2ru.edit_distance_ru <= detox_en2ru.edit_distance_en.quantile(0.99)) \n",
    "    & (detox_en2ru.edit_sim_ru >= detox_en2ru.edit_sim_en.quantile(0.01)) \n",
    "    & (detox_en2ru.edit_sim_ru <= detox_en2ru.edit_sim_en.quantile(0.99))\n",
    "]\n",
    "\n",
    "print(detox_en2ru.shape)\n",
    "print(detox_en2ru_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(detox_en2ru_filtered, random_state=1, test_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 17988\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = DatasetDict({\n",
    "    'train': Dataset.from_dict({'text': train.toxic_ru, 'target': train.neutral_ru}),\n",
    "    'dev': Dataset.from_dict({'text': val.toxic_ru, 'target': val.neutral_ru}),\n",
    "})\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and evaluate baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu import CHRF\n",
    "chrfpp = CHRF(word_order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline chrf++: 60% if not change the texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.09829950381689"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrfpp.corpus_score(val.toxic_ru.tolist(), [val.neutral_ru.tolist()]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A baseline that removes bad words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import wordpunct_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "def detokenize(text):\n",
    "    for symbol in \",.?!'\":\n",
    "        text = text.replace(' ' + symbol, symbol)\n",
    "    return text\n",
    "\n",
    "class Remover:\n",
    "    def __init__(self, ratio_threshold=2):\n",
    "        self.ratio_threshold = ratio_threshold\n",
    "    def fit(self, x, y):\n",
    "        self.x_count = Counter(w.lower() for text in x for w in wordpunct_tokenize(text))\n",
    "        self.y_count = Counter(w.lower() for text in y for w in wordpunct_tokenize(text))\n",
    "    def predict(self, x):\n",
    "        results = []\n",
    "        for text in x:\n",
    "            words = []\n",
    "            for w in wordpunct_tokenize(text):\n",
    "                key = w.lower()\n",
    "                if (self.x_count[key] + 1) / (self.y_count[key] + 1) > self.ratio_threshold:\n",
    "                    continue\n",
    "                words.append(w)\n",
    "            results.append(detokenize(' '.join(words)))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = Remover(2.0)\n",
    "remover.fit(train.toxic_ru, train.neutral_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.00557993346862"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrfpp.corpus_score(remover.predict(val.toxic_ru), [val.neutral_ru.tolist()]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple word-based translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from itertools import product\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# https://johnlekberg.com/blog/2020-10-25-seq-align.html\n",
    "\n",
    "\n",
    "def needleman_wunsch(x, y, sim=None, verbose=False):\n",
    "    \"\"\"Run the Needleman-Wunsch algorithm on two sequences.\n",
    "\n",
    "    x, y -- sequences.\n",
    "\n",
    "    Code based on pseudocode in Section 3 of:\n",
    "\n",
    "    Naveed, Tahir; Siddiqui, Imitaz Saeed; Ahmed, Shaftab.\n",
    "    \"Parallel Needleman-Wunsch Algorithm for Grid.\" n.d.\n",
    "    https://upload.wikimedia.org/wikipedia/en/c/c4/ParallelNeedlemanAlgorithm.pdf\n",
    "    \"\"\"\n",
    "    N, M = len(x), len(y)\n",
    "    if sim is None:\n",
    "        s = lambda a, b: int(a == b)\n",
    "    else:\n",
    "        s = sim\n",
    "\n",
    "    DIAG = -1, -1\n",
    "    LEFT = -1, 0\n",
    "    UP = 0, -1\n",
    "\n",
    "    # Create tables F and Ptr\n",
    "    F = {}\n",
    "    Ptr = {}\n",
    "\n",
    "    F[-1, -1] = 0\n",
    "    for i in range(N):\n",
    "        F[i, -1] = -i\n",
    "    for j in range(M):\n",
    "        F[-1, j] = -j\n",
    "\n",
    "    option_Ptr = DIAG, LEFT, UP\n",
    "    for i, j in product(range(N), range(M)):\n",
    "        option_F = (\n",
    "            F[i - 1, j - 1] + s(x[i], y[j]),\n",
    "            F[i - 1, j] - 1,\n",
    "            F[i, j - 1] - 1,\n",
    "        )\n",
    "        F[i, j], Ptr[i, j] = max(zip(option_F, option_Ptr))\n",
    "\n",
    "    # Work backwards from (N - 1, M - 1) to (0, 0)\n",
    "    # to find the best alignment.\n",
    "    alignment = deque()\n",
    "    i, j = N - 1, M - 1\n",
    "    if verbose:\n",
    "        tq = tqdm(total=max(N, M))\n",
    "        \n",
    "    while i >= 0 and j >= 0:\n",
    "        direction = Ptr[i, j]\n",
    "        if direction == DIAG:\n",
    "            element = i, j\n",
    "        elif direction == LEFT:\n",
    "            element = i, None\n",
    "        elif direction == UP:\n",
    "            element = None, j\n",
    "        alignment.appendleft(element)\n",
    "        di, dj = direction\n",
    "        i, j = i + di, j + dj\n",
    "    while i >= 0:\n",
    "        alignment.appendleft((i, None))\n",
    "        i -= 1\n",
    "    while j >= 0:\n",
    "        alignment.appendleft((None, j))\n",
    "        j -= 1\n",
    "\n",
    "    return list(alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "from tqdm.auto import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TextReplacer:\n",
    "    def __init__(self, max_n=3, smooth_n=10, min_n=10, min_p=0.01):\n",
    "        self.max_n = max_n\n",
    "        self.smooth_n = smooth_n\n",
    "        self.min_n = min_n\n",
    "        self.min_p = min_p\n",
    "        \n",
    "        self.replace_proba = {}\n",
    "        self.replaced_tuples = {}\n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        return nltk.wordpunct_tokenize('_bos_ ' + text + ' _eos_')\n",
    "    \n",
    "    def detokenize(self, text):\n",
    "        text = text.strip()\n",
    "        for symbol in '.,?!':\n",
    "            text = text.replace(' ' + symbol, symbol)\n",
    "        if text.startswith('_bos_'):\n",
    "            text = text[5:]\n",
    "        if text.endswith('_eos_'):\n",
    "            text = text[:-5]\n",
    "        return text.strip()\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        raw_counts = Counter()\n",
    "        replace_counts = Counter()\n",
    "        \n",
    "        for i in trange(len(x_train)):\n",
    "            xx, yy = x_train[i], y_train[i]\n",
    "            xx, yy = self.tokenize(xx), self.tokenize(yy)\n",
    "            alignment = needleman_wunsch(xx, yy)\n",
    "            ixx, iyy = list(zip(*alignment))\n",
    "            for gram_size in range(1, self.max_n + 1):\n",
    "                for start in range(len(ixx) - gram_size + 1):\n",
    "                    xgram = tuple([xx[c] for c in ixx[start: start + gram_size] if c is not None])\n",
    "                    ygram = tuple([yy[c] for c in iyy[start: start + gram_size] if c is not None])\n",
    "                    if xgram:\n",
    "                        xg, yg = ' '.join([''] + list(xgram) + ['']), ' '.join([''] + list(ygram) + [''])\n",
    "                        raw_counts[xg] += 1\n",
    "                        if xgram != ygram:\n",
    "                            replace_counts[(xg, yg)] += 1\n",
    "    \n",
    "        self.replace_proba = defaultdict(list)\n",
    "        self.replaced_tuples = dict()\n",
    "\n",
    "        for pair, n_sub in replace_counts.most_common():\n",
    "            if n_sub >= self.min_n:\n",
    "                xx, yy = pair\n",
    "                pr = n_sub / (self.smooth_n + raw_counts[xx])\n",
    "                if pr >= self.min_p:\n",
    "                    self.replace_proba[xx].append([yy, pr])\n",
    "                    self.replaced_tuples[tuple(xx.strip().split())] = raw_counts[xx]\n",
    "\n",
    "        for k, v in self.replace_proba.items():\n",
    "            tot = sum(p for r, p in v)\n",
    "            if tot < 1:\n",
    "                v.append([k, 1 - tot])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform_one(self, text, n_out=None, temperature=None):\n",
    "        xx = self.tokenize(text)\n",
    "        found_grams = []\n",
    "        for gram_size in range(1, self.max_n + 1):\n",
    "            for start in range(len(xx) - gram_size + 1):\n",
    "                xgram = tuple([c for c in xx[start: start + gram_size] if c is not None])\n",
    "                if xgram and xgram in self.replaced_tuples:\n",
    "                    found_grams.append((xgram, self.replaced_tuples[xgram], len(xgram)))\n",
    "        found_grams = sorted(found_grams, key=lambda x: (x[2], x[1]), reverse=True)\n",
    "        \n",
    "        results = []\n",
    "        for i in range(n_out or 1):\n",
    "            untext = ' '.join([''] + xx + [''])\n",
    "            for gram, gn, gl in found_grams:\n",
    "                gram_text = ' '.join([''] + list(gram) + [''])\n",
    "                reps, ww = zip(*self.replace_proba[gram_text])\n",
    "                if not temperature:\n",
    "                    chosen_rep = list(reps)[np.argmax(ww)]\n",
    "                else: # chose randomly\n",
    "                    weights = [w ** (1 / temperature) for w in ww]\n",
    "                    chosen_rep = random.choices(list(reps), weights=weights)[0]\n",
    "                untext = untext.replace(gram_text, chosen_rep)\n",
    "            results.append(self.detokenize(untext))\n",
    "        if not n_out:\n",
    "            return results[0]\n",
    "        return results\n",
    "    \n",
    "    def transform(self, texts, n_out=None, temperature=None):\n",
    "        return [self.transform_one(text, n_out=n_out, temperature=temperature) for text in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220e4f8be28f4f7b9cca01fd1207d4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17988 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TextReplacer at 0x7ff3d8bca390>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer = TextReplacer(min_n=3)\n",
    "replacer.fit(train.toxic_ru.tolist(), train.neutral_ru.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Какого хуя тут делает этот?'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer.transform_one(\"Какого хуя тут делает этот придурок?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ee36db3aa64373bb51d59d445bb4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "67.35076823754419"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrfpp.corpus_score(replacer.transform(val.toxic_ru), [val.neutral_ru.tolist()]).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare test methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase(\n",
    "    text, model, tokenizer, n=None, max_length=\"auto\", beams=5,\n",
    "):\n",
    "    texts = [text] if isinstance(text, str) else text\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True)[\"input_ids\"].to(\n",
    "        model.device\n",
    "    )\n",
    "\n",
    "    if max_length == \"auto\":\n",
    "        max_length = inputs.shape[1] + 10\n",
    "\n",
    "    result = model.generate(\n",
    "        inputs,\n",
    "        num_return_sequences=n or 1,\n",
    "        do_sample=False,\n",
    "        temperature=1.0,\n",
    "        repetition_penalty=10.0,\n",
    "        max_length=max_length,\n",
    "        min_length=int(0.5 * max_length),\n",
    "        num_beams=beams,\n",
    "        #forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
    "    )\n",
    "    texts = [tokenizer.decode(r, skip_special_tokens=True) for r in result]\n",
    "\n",
    "    if not n and isinstance(text, str):\n",
    "        return texts[0]\n",
    "    return texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/russian_data/test.tsv', sep='\\t')\n",
    "test_inputs = test_data[\"toxic_comment\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune mBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'facebook/mbart-large-50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(base_model)# .cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, padding=True)\n",
    "    labels = tokenizer(examples[\"target\"], padding=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca588f2328be4543b68128f32c9096ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b398c3af564b449cd86d174827c325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_data = raw_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=1, # 8 is too much \n",
    "    weight_decay=1e-5,\n",
    "    max_steps=10_000,\n",
    "    learning_rate=1e-5,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=1,\n",
    "    eval_steps=500, \n",
    "    save_steps=500,\n",
    "    logging_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    # trying to save memory: see https://huggingface.co/docs/transformers/performance\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adafactor\",\n",
    "    gradient_accumulation_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_data[\"train\"],\n",
    "    eval_dataset=tok_data[\"dev\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 17988\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10000\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 1:02:19, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.652800</td>\n",
       "      <td>0.436565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.451400</td>\n",
       "      <td>0.390012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.368482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.408100</td>\n",
       "      <td>0.357230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.363600</td>\n",
       "      <td>0.349286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.315700</td>\n",
       "      <td>0.347586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.326700</td>\n",
       "      <td>0.339857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>0.338116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.315500</td>\n",
       "      <td>0.336197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.254800</td>\n",
       "      <td>0.340212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.336396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>0.336975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.334602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.240100</td>\n",
       "      <td>0.345234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.343958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>0.342643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.221600</td>\n",
       "      <td>0.338574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.342947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.198600</td>\n",
       "      <td>0.346690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.348054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-3500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-5500] due to args.save_total_limit\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-4500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-7500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-8500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-10000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-10000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-9500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/dale/models/detox-parallel/translate-en2ru_yandex-full-mbart/checkpoint-6500 (score: 0.334602415561676).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=0.404996280670166, metrics={'train_runtime': 3740.1318, 'train_samples_per_second': 21.39, 'train_steps_per_second': 2.674, 'total_flos': 8126355688980480.0, 'train_loss': 0.404996280670166, 'epoch': 4.45})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a5009159734ff09c47bb470d0f3832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.33748671933068\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "model.eval()\n",
    "for text in tqdm(val.toxic_ru):\n",
    "    with torch.inference_mode():\n",
    "        out = tokenizer.decode(\n",
    "            model.generate(**tokenizer(text, return_tensors='pt').to(model.device), num_beams=5, max_length=256)[0], \n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "        preds.append(out)\n",
    "        \n",
    "print(chrfpp.corpus_score(preds, [val.neutral_ru.tolist()]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4576     что делать? пожалуйста, скажи, что ты ни хрена с собой не делаешь.\n",
       "7327      пошел ты, rt только что обчистил эту задницу на словах с друзьями\n",
       "7726          полчаса спустя, а он все еще там, \"гребаная ленивая задница\"!\n",
       "16723       я никогда не рассчитывал, что правительство спасет мою задницу.\n",
       "10466                 у нее большая задница, лол, и она встречалась с Канье\n",
       "Name: toxic_ru, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.toxic_ru[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['что делать? пожалуйста, скажите, что вы ничего не делаете',\n",
       " 'ты только что обчистил эту задницу на словах с друзьями',\n",
       " 'полчаса спустя, а он все еще там!',\n",
       " 'Я никогда не рассчитывал на то, что правительство спасет меня',\n",
       " 'У нее большие проблемы, лол, и она встречалась с Канье']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21100541962e4f3f878df81293375fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_outputs = [paraphrase(text, model, tokenizer) for text in tqdm(test_inputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../results/translate-train_yandex-full-mbart/'  # partial training results; need to train further.\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'results_ru.txt', 'w') as f:\n",
    "    for text in test_outputs:\n",
    "        f.write(text+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune mBART with BOTH English (original) and Russian (translated) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 35976\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['text', 'target'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = DatasetDict({\n",
    "    'train': Dataset.from_dict({\n",
    "        'text': train.toxic_ru.tolist() + train.toxic_comment.tolist(), \n",
    "        'target': train.neutral_ru.tolist() + train.neutral_comment.tolist()}),\n",
    "    'dev': Dataset.from_dict({'text': val.toxic_ru, 'target': val.neutral_ru}),\n",
    "})\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'facebook/mbart-large-50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(base_model)# .cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, padding=True)\n",
    "    labels = tokenizer(examples[\"target\"], padding=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f592b1092020441688a3fa4fc53c85a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f422e30f991b4dab8d41d6225c0ebf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_data = raw_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=1, # 8 is too much \n",
    "    weight_decay=1e-5,\n",
    "    max_steps=10_000,\n",
    "    learning_rate=1e-5,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=1,\n",
    "    eval_steps=500, \n",
    "    save_steps=500,\n",
    "    logging_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    # trying to save memory: see https://huggingface.co/docs/transformers/performance\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adafactor\",\n",
    "    gradient_accumulation_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_data[\"train\"],\n",
    "    eval_dataset=tok_data[\"dev\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 35976\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10000\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 1:02:37, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.657300</td>\n",
       "      <td>0.453836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.450800</td>\n",
       "      <td>0.406475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.419700</td>\n",
       "      <td>0.381386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.370062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.361941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.382200</td>\n",
       "      <td>0.359046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.353909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>0.345452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>0.341724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.306900</td>\n",
       "      <td>0.348707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.340284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>0.341694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>0.335481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.334220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.331789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>0.330622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.330019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.300800</td>\n",
       "      <td>0.330058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.264700</td>\n",
       "      <td>0.333875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.267700</td>\n",
       "      <td>0.333650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-10000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-3500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-4500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-5500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-6500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-7500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9000/special_tokens_map.json\n",
      "/home/dale/p3/lib/python3.7/site-packages/transformers/trainer.py:1599: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  args.max_grad_norm,\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9500\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9500/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: target, text. If target, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-10000\n",
      "Configuration saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-10000/config.json\n",
      "Model weights saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [/home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-9500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/dale/models/detox-parallel/translate-en2ru-full_bilingual-mbart/checkpoint-8500 (score: 0.3300188481807709).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=0.45296048736572264, metrics={'train_runtime': 3758.2116, 'train_samples_per_second': 21.287, 'train_steps_per_second': 2.661, 'total_flos': 7893770179706880.0, 'train_loss': 0.45296048736572264, 'epoch': 2.22})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da396d693314ddb97eca5be6523ead0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "model.eval()\n",
    "for text in tqdm(val.toxic_ru):\n",
    "    with torch.inference_mode():\n",
    "        out = tokenizer.decode(\n",
    "            model.generate(**tokenizer(text, return_tensors='pt').to(model.device), num_beams=5, max_length=256)[0], \n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "        preds.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.56487845972582\n"
     ]
    }
   ],
   "source": [
    "print(chrfpp.corpus_score(preds, [val.neutral_ru.tolist()]).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4576     что делать? пожалуйста, скажи, что ты ни хрена с собой не делаешь.\n",
       "7327      пошел ты, rt только что обчистил эту задницу на словах с друзьями\n",
       "7726          полчаса спустя, а он все еще там, \"гребаная ленивая задница\"!\n",
       "16723       я никогда не рассчитывал, что правительство спасет мою задницу.\n",
       "10466                 у нее большая задница, лол, и она встречалась с Канье\n",
       "Name: toxic_ru, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.toxic_ru[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['что делать? пожалуйста, скажите, что ты ничего не делаешь с собой.',\n",
       " 'Ты только что обчистил его на словах с друзьями',\n",
       " 'полчаса спустя, а он все еще там!',\n",
       " 'Я никогда не рассчитывал, что правительство спасет меня.',\n",
       " 'У нее большие проблемы, лол, и она встречалась с Канье']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891128919a2e4b2ba96d837b7cad6de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_outputs = [paraphrase(text, model, tokenizer) for text in tqdm(test_inputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../results/translate-train_yandex-full_bilingual-mbart/'  # partial training results; need to train further.\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'results_ru.txt', 'w') as f:\n",
    "    for text in test_outputs:\n",
    "        f.write(text+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python evaluate_ru.py \\\n",
    "    --result_filename scores \\\n",
    "    --input_dir results/translate-train_yandex-full-mbart \\\n",
    "    --output_dir results\n",
    "    \n",
    "Style accuracy:       0.4556241035461426\n",
    "Meaning preservation: 0.8801424503326416\n",
    "Joint fluency:        -0.10965493321418762\n",
    "Joint score:          -0.04347466304898262\n",
    "Scores after calibration:\n",
    "Style accuracy:       0.5100616812705994\n",
    "Meaning preservation: 0.8203034400939941\n",
    "Joint fluency:        0.8738968372344971\n",
    "Joint score:          0.35575705766677856\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python evaluate_ru.py \\\n",
    "    --result_filename scores \\\n",
    "    --input_dir results/translate-train_yandex-full_bilingual-mbart \\\n",
    "    --output_dir results\n",
    "    \n",
    "Style accuracy:       0.5160583257675171\n",
    "Meaning preservation: 0.9036513566970825\n",
    "Joint fluency:        -0.07349134981632233\n",
    "Joint score:          -0.03711703419685364\n",
    "Scores after calibration:\n",
    "Style accuracy:       0.5644525289535522\n",
    "Meaning preservation: 0.8554770350456238\n",
    "Joint fluency:        0.9154849648475647\n",
    "Joint score:          0.422428697347641\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3k",
   "language": "python",
   "name": "p3k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
